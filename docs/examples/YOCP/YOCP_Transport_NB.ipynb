{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301f7194-e559-4d16-a538-2634afb87a37",
   "metadata": {},
   "source": [
    "# Viscosity Coefficients\n",
    "\n",
    "## Prelude\n",
    "In this notebook we will calculate the viscosity of the Yukawa OCP.\n",
    "\n",
    "The YAML input file can be found at [input_file](https://raw.githubusercontent.com/murillo-group/sarkas/master/docs/examples/YOCP/input_files/yocp_transport.yaml) and this notebook at [notebook](https://raw.githubusercontent.com/murillo-group/sarkas/master/docs/examples/YOCP/YOCP_Transport_NB.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea21cc-faae-4d78-a033-5c73e06b0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the usual libraries\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "plt.style.use('MSUstyle')\n",
    "\n",
    "# Import sarkas\n",
    "from sarkas.processes import Simulation, PostProcess, PreProcess\n",
    "\n",
    "\n",
    "# Create the file path to the YAML input file\n",
    "input_file_name = os.path.join('input_files', 'yocp_transport.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db6ac5-ec00-473d-8635-08801009449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre = PreProcess(input_file_name)\n",
    "# pre.setup(read_yaml=True)\n",
    "# pre.run(loops=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc363c1d-5fd8-409f-9bf6-d9ed16ac44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = Simulation(input_file_name)\n",
    "# sim.setup(read_yaml=True)\n",
    "# sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87157209-602b-4364-acb5-578cae560dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc = PostProcess(input_file_name)\n",
    "postproc.setup(read_yaml=True)\n",
    "# postproc.parameters.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839c055-948a-4cd4-9b2b-03620449709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarkas.tools.observables import Thermodynamics, PressureTensor, HeatFlux, RadialDistributionFunction, VelocityAutoCorrelationFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f991c-71ad-4eb7-ad6f-2fd1d89085c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "therm = Thermodynamics()\n",
    "therm.setup(postproc.parameters, no_slices=3 )\n",
    "therm.compute()\n",
    "therm.grab_sim_data()\n",
    "therm.temp_energy_plot(postproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197d5cf-8009-4040-ac40-2ac2d5a97a6a",
   "metadata": {},
   "source": [
    "## Pair Distribution Function\n",
    "\n",
    "The first observable to calculate is always the RDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33ed48-0262-4692-9932-b5ee5722b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = RadialDistributionFunction()\n",
    "rdf.setup(postproc.parameters, no_slices=3 )\n",
    "rdf.parse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b76b82-86eb-4a18-b097-0fab499113bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.plot(scaling = rdf.a_ws, \n",
    "         y = ('C-C RDF', 'Mean'),\n",
    "         xlabel = r'$r /a$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1bde8e-c4f1-485d-ae71-7d77d7abad66",
   "metadata": {},
   "source": [
    "## Pressure Tensor\n",
    "\n",
    "The viscosity is obtained from the autocorrelation function of the Pressure Tensor $\\overleftrightarrow{\\mathcal P}$ whose elements are\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal P_{\\alpha\\gamma}(t) = \\frac{1}{V} \\sum_{i}^{N} \\left [ m_i v^{\\alpha}_{i} v^{\\gamma}_{i} -  \\sum_{j > i} \\frac{r_{ij}^{\\alpha} r_{ij}^{\\gamma} }{r_{ij}} \\frac{d}{dr}\\phi(r) \\right ],\n",
    "\\end{equation}\n",
    "\n",
    "where $r_{ij}^{\\alpha}$ is the $\\alpha$ component of the distance between particles $i$ and $j$. The first term is the kinetic term and the second term is the virial term, but it is often referred to as the potential contribution. The virial is calculated during the simulation phase and saved together with particles corrdinates. \n",
    "\n",
    "In order to check that our code are correct, let's verify some laws. \n",
    "\n",
    "The pressure of the system is calculated from $\\mathcal P(t)= \\frac1{3} {\\rm Tr} \\overleftrightarrow{\\mathcal P}(t)$ and also from \n",
    "\n",
    "\\begin{equation}\n",
    "P = \\frac{n}{\\beta} - \\frac{2\\pi}{3} n^2 \\int_0^{\\infty} dr \\, r^3 \\frac{d\\phi(r)}{dr} g(r)\n",
    "\\end{equation}\n",
    "\n",
    "where $g(r)$ is the pair distribution function that we have already calculated.\n",
    "\n",
    "Let's calculate the Pressure tensor and the pressure $\\mathcal P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2404f8b-aeb9-4a13-85bc-945ae029875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PressureTensor()\n",
    "pt.setup(postproc.parameters, no_slices = 3)\n",
    "# pt.compute()\n",
    "pt.parse(acf_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d32c05-88d0-4ff9-b3b5-8fb1fdb981f6",
   "metadata": {},
   "source": [
    "As usual the data is saved in several dataframes. In this case we have 4 dataframes\n",
    "\n",
    "* A dataframe for the values of each of the elements of the pressure tensor for each of the slices, `pt.dataframe_slices`\n",
    "* A dataframe for the mean and std values of each of the elements of the pressure tensor, `pt.dataframe`\n",
    "* A dataframe for the ACF of each pair $\\langle \\mathcal P_{\\alpha\\beta}(t)\\mathcal P_{\\mu\\nu}(0) \\rangle$ for each slice, `pt.dataframe_acf_slices`\n",
    "* A dataframe for the mean and std of the ACF of each pair $\\langle \\mathcal P_{\\alpha\\beta}(t)\\mathcal P_{\\mu\\nu}(0) \\rangle$, `pt.dataframe_acf`\n",
    "\n",
    "Let's look at `pt.dataframe` and at its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d3927-a905-43c7-a8b0-b6b30450cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912672a-78a9-42a2-8066-4fdd9fa3f482",
   "metadata": {},
   "source": [
    "Note that the Pressure $\\mathcal P(t)$ is readily calculated and provided as a column of the dataframe.\n",
    "\n",
    "Note also that there is a multitude of columns. This is because in dense plasmas it is useful to know the contribution of both the kinetic term and potential term separately, as such the columns of each dataframe contain the kinetic, the potential, and the total value of each $\\mathcal P_{\\alpha\\beta}$ and their ACFs.\n",
    "\n",
    "Let's plot the Pressure as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b597cc-caeb-428b-8fac-7b93356e74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot it\n",
    "t_wp = 2.0*np.pi/therm.total_plasma_frequency\n",
    "\n",
    "p_id = pt.total_num_density / therm.beta_slice.mean()\n",
    "ax = pt.plot( \n",
    "    scaling = (t_wp, p_id),\n",
    "    y = (\"Total\",\"Pressure\", \"Mean\"),\n",
    "    xlabel = \"Plasma cycles\",\n",
    "    ylabel = r\"$ \\beta P(t)/n$\"\n",
    "       )\n",
    "ax.plot(pt.dataframe[(\"Species\", \"Quantity\", 'Time')]/t_wp, pt.dataframe[(\"Total\",'Pressure','Mean')].expanding().mean()/p_id )\n",
    "ax.legend(['Pressure', 'Moving avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef3e1c-a7fd-4ae5-b1f8-b32f075c0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarkas.tools.observables import make_gaussian_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbf309-ba04-41f1-8354-c0c3d20b5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b53e5f-e193-4845-bd44-d5933e826cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gaussian_plot(pt.dataframe[(\"Species\", \"Quantity\", 'Time')]/t_wp, pt.dataframe[(\"C\",'Pressure Tensor XY','Mean')], \"Pressure Tensor XY\", \"mks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce8467-1b38-4637-a2a2-e2f29e9de5f2",
   "metadata": {},
   "source": [
    "## Pressure from RDF\n",
    "\n",
    "Let's now calculate the pressure from the integral of the RDF. This is obtained from the method `compute_from_rdf` of the `Thermodynamics` object. \n",
    "\n",
    "Looking at the documentation of this [method](:meth:`sarkas.tool.observables.Thermodynamics.compute_from_rdf`) we notice that it returns five values:\n",
    "the Hartree and correlational terms between species :math:`A` and :math:`B` and the ideal pressure $n k_B T$. \n",
    "\n",
    "The total pressure is given from the sum of the three terms and should be equal to the \n",
    "\n",
    "$$ P = n k_BT + P_{\\rm Hartree} + P_{\\rm Corr} = {\\operatorname {Mean} } \\left \\{ \\mathcal P(t) \\right \\} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a096ec9-e033-4064-a77e-ead10f6999f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nkT, _, _, p_h, p_c = therm.compute_from_rdf(rdf, postproc.potential)\n",
    "\n",
    "P_rdf = nkT + p_h + p_c\n",
    "P_trace = pt.dataframe[(\"Total\",\"Pressure\", \"Mean\")].mean()\n",
    "\n",
    "print(\"The relative difference between the two methods is = {:.2f} %\".format((P_rdf[0] - P_trace)*100/P_rdf[0] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1bdf1-a468-4408-8215-349c6ce87023",
   "metadata": {},
   "source": [
    "It seems that we have done a good job! \n",
    "\n",
    "### Sum rule\n",
    "\n",
    "Let's now check that we have calculated the ACF correctly. The equal time ACFs of the elements of $\\overleftrightarrow{\\mathcal P}(t)$ obey the following sum rules\n",
    "\n",
    "$$\n",
    "\\mathcal J_{zzzz}(0) = \\frac 13 \\sum_{\\alpha}\\left \\langle \\mathcal P_{\\alpha\\alpha}(0)\\mathcal P_{\\alpha\\alpha}(0) \\right \\rangle  =  \\frac{n}{\\beta^2} \\left [ 3 + \\frac{2\\beta}{15} I_1 + \\frac \\beta5 I_2 \\right ] ,\n",
    "$$ \n",
    "$$\n",
    "\\mathcal J_{zzxx}(0) = \\frac 16 \\sum_{\\alpha} \\sum_{\\beta\\neq\\alpha} \\left \\langle \\mathcal P_{\\alpha\\alpha}(0)\\mathcal P_{\\beta\\beta}(0) \\right \\rangle = \\frac{n}{\\beta^2} \\left [ 1 - \\frac{2\\beta}{5} I_1 + \\frac \\beta{15} I_2 \\right ] ,\n",
    "$$ \n",
    "$$\n",
    "\\mathcal J_{xyxy}(0) = \\frac 16 \\sum_{\\alpha}\\sum_{\\beta \\neq \\alpha} \\left \\langle \\mathcal P_{\\alpha\\beta}(0)\\mathcal P_{\\alpha\\beta}(0) \\right \\rangle = \\frac{n}{\\beta^2} \\left [ 1 + \\frac{4\\beta}{15} I_1 + \\frac \\beta{15} I_2 \\right ] ,\n",
    "$$ \n",
    "\n",
    "where\n",
    "\n",
    "$$ \n",
    "I_1 = 2\\pi n \\int dr \\, g(r) r^3 \\frac{d\\phi}{dr}, \\quad I_2 = 2\\pi n \\int dr\\, g(r) r^4 \\frac{d^2\\phi}{dr^2}.\n",
    "$$\n",
    "\n",
    "Notice that all three equal time ACF satisfy \n",
    "\n",
    "$$ \\mathcal J_{zzzz}(0) - \\mathcal J_{zzxx}(0) = 2 \\mathcal J_{xyxy}(0) .$$\n",
    "\n",
    "Let's look at the dataframe of the ACF first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527d555-bca1-431b-9ba1-329e85e4d7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.dataframe_acf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49023915-cffb-448e-b2ec-0dc6e0bd8203",
   "metadata": {},
   "source": [
    "Notice that in this case we have many more columns since now we have the ACF of the kinetic-kinetic, kinetic-potential, potential-kinetic, potential-potential, and the total ACF of each pair of elements.\n",
    "\n",
    "Let's verify the sum rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672990c-5b2c-4ef4-a579-8e0b9fd7c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagonal terms\n",
    "column_zzzz = [\n",
    "    ('Pressure Tensor ACF XXXX', 'Mean'),\n",
    "     ('Pressure Tensor ACF YYYY', 'Mean'),\n",
    "     ('Pressure Tensor ACF ZZZZ', 'Mean'),\n",
    "]\n",
    "J_zzzz_0 = pt.dataframe_acf[column_zzzz].iloc[0].mean()\n",
    "\n",
    "# Cross-Diagonal Terms\n",
    "column_zzxx = [\n",
    "    ('Pressure Tensor ACF XXYY', 'Mean'),\n",
    "    ('Pressure Tensor ACF XXZZ', 'Mean'),\n",
    "    ('Pressure Tensor ACF YYZZ', 'Mean'),\n",
    "]\n",
    "J_zzxx_0 = pt.dataframe_acf[column_zzxx].iloc[0].mean()\n",
    "\n",
    "# Cross Off Diagonal terms\n",
    "column_xyxy = [\n",
    "    ('Pressure Tensor ACF XYXY', 'Mean'),\n",
    "    ('Pressure Tensor ACF XZXZ', 'Mean'),\n",
    "    ('Pressure Tensor ACF YZYZ', 'Mean'),\n",
    "]\n",
    "J_xyxy_0 = pt.dataframe_acf[column_xyxy].iloc[0].mean()\n",
    "\n",
    "# The units of J's are [Density *  Energy]^2\n",
    "\n",
    "print('The isotropy condition : (J_zzzz_0 - J_zzxx_0 )/( 2*J_xyxy_0 ) = {:.4f}'.format( (J_zzzz_0 - J_zzxx_0)/(2.0 * J_xyxy_0)  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc268b3e-f5ee-40f4-9552-6cf53fcfec51",
   "metadata": {},
   "source": [
    "Not exactly 1 but pretty close.\n",
    "\n",
    "Let's now verify the sum rules. These are calculated from the `pt.sum_rule` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743596e-d061-4752-bb2e-323ee7f2a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_r, c_r = rdf.compute_sum_rule_integrals(postproc.potential)\n",
    "sigma_zzzz, sigma_zzxx, sigma_xyxy = pt.sum_rule(therm.beta_slice.mean(), rdf, postproc.potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423d71c-d369-4602-85f3-28321a8a1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_inf = J_xyxy_0*therm.beta_slice.mean()*rdf.box_volume\n",
    "K_inf = 1.0/3.0*(J_zzzz_0 + 2.0* J_zzxx_0)*therm.beta_slice.mean()*rdf.box_volume\n",
    "\n",
    "K_sr = (sigma_zzzz + 2.0*sigma_zzxx)/3.0\n",
    "\n",
    "const = 1.0 #postproc.species[0].sigma**3/postproc.species[0].epsilon\n",
    "\n",
    "print(\"G_inf = {:2.1f}, sum_rule = {:2.1f}, {:2.2f} %\".format( G_inf* const, sigma_xyxy * const, 100*abs(G_inf -  sigma_xyxy) /G_inf) )\n",
    "print(\"K_inf = {:2.1f}, sum_rule = {:2.1f}, {:2.2f} %\".format( K_inf * const,  K_sr * const, 100*abs(K_inf -  K_sr) /K_inf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92baa663-f704-4be5-9f0c-a8fdeaa34724",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Viscosity\n",
    "\n",
    "The shear viscosity is calculated from the Green-Kubo relation\n",
    "\n",
    "\\begin{equation}\n",
    "\\eta = \\frac{\\beta V}{3} \\sum_{\\alpha} \\sum_{\\gamma \\neq \\alpha} \\int_0^{\\infty} dt \\, \\left \\langle \\mathcal P_{\\alpha\\gamma}(t) \\mathcal P_{\\alpha\\gamma}(0) \\right \\rangle,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\beta = 1/k_B T$, $\\alpha,\\gamma = {x, y, z}$.\n",
    "\n",
    "The bulk viscosity is given by a similar relation\n",
    "\n",
    "\\begin{equation}\n",
    "\\eta_V = \\beta V \\int_0^{\\infty}dt \\,  \\left \\langle \\delta \\mathcal P(t) \\delta \\mathcal P(0) \\right \\rangle,\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta \\mathcal P(t) = \\mathcal P(t) - \\left \\langle \\mathcal P  \\right \\rangle\n",
    "\\end{equation}\n",
    "\n",
    "is the deviation of the scalar pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b34546-3647-4e6f-8410-b9797e069bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarkas.tools.transport import Viscosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773352d-9438-4a5c-b336-76aecdb4f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = Viscosity()\n",
    "tc.setup(postproc.parameters, observable=pt)\n",
    "tc.compute(observable = pt)\n",
    "# tc.parse(observable = pt, tc_name = \"Viscosities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e1b52-c9ad-46b8-977b-841b03b907cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_str = \"Delta Pressure ACF\"\n",
    "acf_avg = pt.dataframe_acf[(\"Pressure Bulk ACF\", \"Mean\")]\n",
    "acf_std = pt.dataframe_acf[(\"Pressure Bulk ACF\", \"Std\")]\n",
    "\n",
    "pq = \"Bulk Viscosity\"\n",
    "tc_avg = tc.dataframe[(pq, \"Mean\")]\n",
    "tc_std = tc.dataframe[(pq, \"Std\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbce634-539c-494b-9327-39cabcbac6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f7c85-4af0-4b53-a3c5-d4d23041a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = tc.plot_tc(\n",
    "    time = tc.dataframe[(\"Integration\",\"Interval\")].to_numpy(),\n",
    "    acf_data=np.column_stack((acf_avg, acf_std)),\n",
    "    tc_data=np.column_stack((tc_avg, tc_std)),\n",
    "    acf_name=acf_str,\n",
    "    tc_name=\"Bulk Viscosity\",\n",
    "    figname=\"{}_Plot.png\".format(\"Bulk Viscosity\"),\n",
    "    show=False\n",
    ")\n",
    "axes[0].set(ylim = (-1, 1.05))\n",
    "# axes[1].set(ylim = (-0.5, 1000 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b9c25-d4f0-4da8-94df-8255b70a0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def murillo_yvm(kappa, gamma):\n",
    "    Ak = 0.46 *kappa**4/(1 + 0.44 * kappa**4)\n",
    "    Bk = 1.01*np.exp(-0.92 * kappa)\n",
    "    Ck = -3.7e-5 + 9.0e-4 * kappa - 2.9e-4*kappa**2\n",
    "    \n",
    "    gamma_ocp = Ak + Bk * gamma  + Ck*gamma**2\n",
    "    lambda_yvm = 4.0 * np.pi/3.0 * (3.0 * gamma_ocp)**(3/2)\n",
    "    I1 = 1.0/ (180 * gamma_ocp * np.pi **(3/2) )\n",
    "    I2 = (0.49 - 2.23 * gamma_ocp**(-1/3) )/ (60 *np.pi**2)\n",
    "    I3 = 0.241 * gamma_ocp**(1/9)/np.pi**(3/2)\n",
    "    \n",
    "    eta = lambda_yvm * I1 + (1 + lambda_yvm * I2)**2/(lambda_yvm * I3)\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be184e5f-18c7-4752-8fc3-c8375b5e57f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pq = \"Shear Viscosity\"\n",
    "tc_avg = tc.dataframe[(pq, \"Mean\")]\n",
    "tc_std = tc.dataframe[(pq, \"Std\")]\n",
    "\n",
    "\n",
    "rescale = pt.total_plasma_frequency * pt.a_ws**2 * pt.species_masses[0] * pt.total_num_density\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(tc.dataframe[(\"Integration\",\"Interval\")].to_numpy()*1e12,\n",
    "       tc_avg / rescale,\n",
    "       label = r'$\\mu$')\n",
    "\n",
    "ax.fill_between(\n",
    "    tc.dataframe[(\"Integration\",\"Interval\")].to_numpy()*1e12,\n",
    "    (tc_avg - tc_std) / rescale,\n",
    "    (tc_avg + tc_std) / rescale,\n",
    "    alpha = 0.2)\n",
    "\n",
    "ax.plot(tc.dataframe[(\"Integration\",\"Interval\")].to_numpy()*1e12,\n",
    "       tc_avg.expanding().mean()/rescale,\n",
    "       label = r'Moving avg')\n",
    "ax.set(xlabel = r'Time lag $\\tau$ [ps]',\n",
    "      ylabel = r\"Shear viscosity $\\eta$\",\n",
    "      xscale=  'log'\n",
    "      )\n",
    "eta_yvm = murillo_yvm(postproc.potential.kappa, postproc.potential.coupling_constant)\n",
    "ax.axhline(0.0654, ls = '--', c = 'r', label = \"Daligault MD\")\n",
    "ax.axhline(eta_yvm, ls = ':', c = 'r', label = \"Murillo YVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6c046-0f89-47fe-b575-2e83ced7727e",
   "metadata": {},
   "source": [
    "## Thermal Conductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6645c34-d6ae-43a3-9516-dd57b9630146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarkas.tools.observables import HeatFlux\n",
    "from sarkas.tools.transport import ThermalConductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a166357-a5e2-47af-8115-885a22c2cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = HeatFlux()\n",
    "ht.setup(postproc.parameters, no_slices=3)\n",
    "ht.compute(calculate_acf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8d116-6f49-4579-890a-d1c1c0936fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "thc = ThermalConductivity()\n",
    "thc.setup(postproc.parameters, ht)\n",
    "thc.compute(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584aad11-56f3-491c-a3a1-5a5134f873c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
